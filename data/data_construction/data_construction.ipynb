{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Set the number of random entries to select\n",
    "num_entries = 50000\n",
    "\n",
    "# Read the original dataset\n",
    "with open('../json_data/full_coordinate_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random entries\n",
    "random_entries = random.sample(data, num_entries)\n",
    "\n",
    "json_elements = []\n",
    "\n",
    "for entry in random_entries:\n",
    "    json_object = {\n",
    "        'id': entry['id'],\n",
    "        'conversations': entry['conversations']\n",
    "    }\n",
    "    json_elements.append(json_object)\n",
    "\n",
    "# Convert the json_elements list to a JSON string\n",
    "json_string = json.dumps(json_elements)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open('small_train.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(json_elements, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "with open(f\"k_{k}_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(\"json_data/small_train.json\", \"r\") as file:\n",
    "    indexes = json.load(file)\n",
    "\n",
    "# Updated processing to include both original and augmented data points with images in the prompt\n",
    "small_data = []\n",
    "\n",
    "for i, data_index in enumerate(indexes):\n",
    "    index = int(data_index['id'].split(\"_\")[1])\n",
    "    for j in range(k):\n",
    "        quadrant_item = data[index*(k + 1) + j]\n",
    "        quadrant_item['id'] = f\"identity_{i}_{j}\"\n",
    "        small_data.append(quadrant_item)\n",
    "        \n",
    "    coordinate_item = data[index*(k + 1) + k]\n",
    "    coordinate_item['id'] = f\"identity_{i}_{k}\"\n",
    "    small_data.append(coordinate_item)\n",
    "\n",
    "# Save the updated augmented data to a new JSON file\n",
    "augmented_file_path = f\"json_data/small_k_{k}_train.json\"\n",
    "with open(augmented_file_path, \"w\") as file:\n",
    "    json.dump(small_data, file, indent=4)\n",
    "# create augmented data where one data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file to examine its structure\n",
    "csv_file_path = 'data-recursive-main-fixed.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the JSON format to include two entries for quadrant and one for position per image sequence\n",
    "data_k1 = data[data['k'] == 1].copy()\n",
    "data_k2 = data[data['k'] == 2].copy()\n",
    "data_k3 = data[data['k'] == 3].copy()\n",
    "\n",
    "# Merge the data for k=1, 3\n",
    "merged_data = pd.merge(data_k1, data_k2, on=['img_filename', 'instruction'], suffixes=('_k1', '_k2',))\n",
    "print(len(merged_data))\n",
    "merged_data = pd.merge(merged_data, data_k3, on=['img_filename', 'instruction'], suffixes=('', '_k3'))\n",
    "print(len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "K = 2\n",
    "\n",
    "csv_file_path = '../data-recursive-main.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data.head()\n",
    "\n",
    "datas = []\n",
    "for k in range(1, K + 2):\n",
    "    data_k = data[data['k'] == k].copy()\n",
    "    datas.append(data_k)\n",
    "\n",
    "merged_data = datas[0]\n",
    "for k in range(1, K + 1):\n",
    "    merged_data = pd.merge(merged_data, datas[k], on=['img_filename', 'instruction'], suffixes=(f'_{k-1}', f'_{k}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reinitialize the JSON data list\n",
    "json_data = []\n",
    "for index, row in merged_data.iterrows():\n",
    "    if row[\"instruction\"] == \"\":\n",
    "        continue\n",
    "    # Entry for quadrant prediction using k=1 image\n",
    "    entry1 = {\n",
    "        \"id\": f\"identity_{index}_0\",\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Picture 1: <img>data/recursive_augmented_images/{row['new_name_k1']}</img>\\n In this UI screenshot, what is the partition of the element corresponding to the command \\\"{row['instruction']}\\\" (with quadrant number)?\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": str(row['quadrant_k1'])\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Entry for quadrant prediction using k=2 image\n",
    "    entry2 = {\n",
    "        \"id\": f\"identity_{index}_1\",\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Picture 1: <img>data/recursive_augmented_images/{row['new_name_k2']}</img>\\n In this UI screenshot, what is the partition of the element corresponding to the command \\\"{row['instruction']}\\\" (with quadrant number)?\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": str(row['quadrant_k2'])\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    x = float(row['point'].split(',')[0].split('(')[1])\n",
    "    y = float(row['point'].split(',')[1].split(')')[0])\n",
    "    rounded_x = round(x, 2)\n",
    "    rounded_y = round(y, 2)\n",
    "\n",
    "    # Entry for position prediction using k=2 image\n",
    "    entry3 = {\n",
    "        \"id\": f\"identity_{index}_2\",\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Picture 1: <img>data/recursive_augmented_images/{row['new_name']}</img>\\n In this UI screenshot, what is the position of the element corresponding to the command \\\"{row['instruction']}\\\" (with point)?\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"({rounded_x}, {rounded_y})\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    json_data.append(entry1)\n",
    "    json_data.append(entry2)\n",
    "    json_data.append(entry3)\n",
    "\n",
    "# Save to a JSON file with the new format\n",
    "json_output_path = 'k_2_data.json'\n",
    "with open(json_output_path, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "json_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "AUGMENTED_PER_POINT = 3\n",
    "\n",
    "# Load the CSV file to examine its structure\n",
    "csv_file_path = '../data-recursive-main.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "json_data = []\n",
    "for i in range(0, len(data), AUGMENTED_PER_POINT):\n",
    "    for k in range(K):\n",
    "        row = data.iloc[i + k]\n",
    "        json_object = {\n",
    "            \"id\": f\"identity_{i//AUGMENTED_PER_POINT}_{k}\",\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"user\",\n",
    "                    \"value\": f\"Picture 1: <img>data/recursive_augmented_images/{row['new_name']}</img>\\n In this UI screenshot, what is the partition of the element corresponding to the command \\\"{row['instruction']}\\\" (with quadrant number)?\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"assistant\",\n",
    "                    \"value\": str(row['quadrant'])\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        json_data.append(json_object)\n",
    "\n",
    "    row = data.iloc[i + K]\n",
    "    \n",
    "    x = float(row['point'].split(',')[0].split('(')[1])\n",
    "    y = float(row['point'].split(',')[1].split(')')[0])\n",
    "    rounded_x = round(x, 2)\n",
    "    rounded_y = round(y, 2)\n",
    "\n",
    "    json_object = {\n",
    "                    \"id\": f\"identity_{i//AUGMENTED_PER_POINT}_{K}\",\n",
    "                    \"conversations\": [\n",
    "                        {\n",
    "                            \"from\": \"user\",\n",
    "                            \"value\": f\"Picture 1: <img>data/recursive_augmented_images/{row['new_name']}</img>\\n In this UI screenshot, what is the position of the element corresponding to the command \\\"{row['instruction']}\\\" (with point)?\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"from\": \"assistant\",\n",
    "                            \"value\": f\"({rounded_x}, {rounded_y})\",\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "    json_data.append(json_object)\n",
    "\n",
    "with open(f'k_{K}_data.json', 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a json list of 9501 random indices from 0 to 113141\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set the number of random indices to select\n",
    "num_entries = 9501\n",
    "\n",
    "# Select random indices\n",
    "random_entries = random.sample(range(112764), num_entries)\n",
    "\n",
    "# Convert the random indices to a JSON string\n",
    "json_string = json.dumps(random_entries)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open('random_indices.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(random_entries, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load the JSON file containing the random indices\n",
    "with open('../json_data/random_indices.json', 'r') as file:\n",
    "    random_indices = json.load(file)\n",
    "\n",
    "# make random_indices a set for faster lookup\n",
    "random_indices = set(random_indices)\n",
    "\n",
    "test_indices = set()\n",
    "# make a new json list of 500 different random indices from 0 to 112764\n",
    "num_entries = 500\n",
    "for i in range(num_entries):\n",
    "    print(i)\n",
    "    ith_entry = random.randint(0, 112764)\n",
    "    while ith_entry in random_indices or ith_entry in test_indices:\n",
    "        ith_entry = random.randint(0, 112764)\n",
    "    test_indices.add(ith_entry)\n",
    "\n",
    "test_indices = list(test_indices)\n",
    "\n",
    "# Convert the random indices to a JSON string\n",
    "json_string = json.dumps(test_indices)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open('test_indices.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(test_indices, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'seeclick_web_bbox.csv'\n",
    "data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "index = 0\n",
    "for i in range(0, len(data)):\n",
    "    row = data.iloc[i]\n",
    "    if row['instruction'] == ' ' or row['instruction'] == '' or row['instruction'] == '.':\n",
    "        continue\n",
    "    bbox = \"(\" + row['bbox'].split('[')[1].split(']')[0] + \")\"\n",
    "    json_object = {\n",
    "        \"image\": \"./train_data/\"+row['img_filename'],\n",
    "        \"command\": row['instruction'],\n",
    "        \"bbox\": bbox\n",
    "    }\n",
    "\n",
    "    json_data.append(json_object)\n",
    "\n",
    "with open('seeclick_web_bbox.json', 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source and destination directories\n",
    "source_dir = \"../downloads/mobile_images/combined/\"\n",
    "destination_dir = \"../images/\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the source directory\n",
    "for filename in os.listdir(source_dir):\n",
    "    # Check if the file is a .jpg image\n",
    "    if filename.lower().endswith(\".jpg\"):\n",
    "        # Construct full file paths\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "        destination_file = os.path.join(destination_dir, filename)\n",
    "        \n",
    "        # Move the file\n",
    "        shutil.move(source_file, destination_file)\n",
    "\n",
    "print(\"All .jpg images have been moved to ../images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "# preprocess images for ReVL\n",
    "data_path = \"../json_data/ReVL_text_to_point_10000.json\"\n",
    "with open(data_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    entry = data[i]\n",
    "    if entry[\"type\"] == \"revl\":\n",
    "        for step in entry[\"conversations\"]:\n",
    "            if step[\"from\"] == \"user\":\n",
    "                zoom = step[\"zoom\"]\n",
    "                img_path = step[\"Image\"]\n",
    "                # print(img_path)\n",
    "                # print(zoom)\n",
    "                img = Image.open(\"../../\" + img_path)\n",
    "                width, height = img.size\n",
    "                # zoom is a normalized bounding box in the format (left, upper, right, lower)\n",
    "                left = int(zoom[0] * width)\n",
    "                upper = int(zoom[1] * height)\n",
    "                right = int(zoom[2] * width)\n",
    "                lower = int(zoom[3] * height)\n",
    "                zoomed_img = img.crop((left, upper, right, lower))\n",
    "                # save the zoomed in image with zoom coordinates in the filename\n",
    "                new_img_path = img_path.replace(\".png\", f\"_{left}_{upper}_{right}_{lower}.png\")\n",
    "                # show before and after images\n",
    "                # display(img)\n",
    "                # display(zoomed_img)\n",
    "                # print(new_img_path)\n",
    "                zoomed_img.save(\"../../\" + new_img_path)\n",
    "                step[\"value\"] = f\"<img>{new_img_path}</img>\\n\" + step[\"value\"]\n",
    "                # print(step[\"value\"])\n",
    "\n",
    "# save the updated data to a new JSON file\n",
    "updated_data_path = data_path.replace(\".json\", \"_with_augmented_images.json\")\n",
    "with open(updated_data_path, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAABAAEDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigD//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAIAAACQd1PeAAAADElEQVR4AWP4//8/AAX+Av4fbPrrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1x1>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "image = Image.open(\"../images/21942.jpg\")\n",
    "\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
